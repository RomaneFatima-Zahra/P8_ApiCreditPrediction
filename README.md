# ğŸ§  API de PrÃ©diction de SolvabilitÃ© Client

Cette API permet dâ€™Ã©valuer la **solvabilitÃ© dâ€™un client** pour statuer sur une demande de prÃªt.  
Elle sâ€™appuie sur un modÃ¨le de **Machine Learning** (`model.pkl`) pour prÃ©dire si un client est **solvable** ou **dÃ©faillant**, Ã  partir de ses donnÃ©es personnelles,  socio-Ã©conomiques et de son profil.

## Contexte : 

Ce projet consiste Ã  dÃ©ployer en production un modÃ¨le de scoring de crÃ©dit via une API, avec monitoring et CI/CD automatisÃ©.

Objectifs principaux :

CrÃ©er une API FastAPI fonctionnelle
Conteneuriser avec Docker
Mettre en place un pipeline CI/CD
Monitorer le modÃ¨le en production (Data Drift)
Optimiser les performances

---

## ğŸš€ FonctionnalitÃ©s

- âœ… **Endpoint principal `/predict`** pour obtenir une prÃ©diction de solvabilitÃ©.  
- ğŸ§© **Validation stricte des donnÃ©es** via des modÃ¨les `Pydantic`.  
- ğŸ§¾ **Logs structurÃ©s en JSON** dans `logs/api_logger.log`.  
- ğŸ§ª **Tests unitaires et dâ€™intÃ©gration** (via `pytest`).  
- ğŸ³ **Image Docker** prÃªte Ã  Ãªtre dÃ©ployÃ©e.

---

## ğŸ§± Structure du projet

```
ğŸ“¦ ApiCreditPrediction
â”œâ”€â”€ API_Fastapi.py
â”œâ”€â”€ model.pkl
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ test_unitaires.py
â”œâ”€â”€ test_integration.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ app_monitoring.py
â”œâ”€â”€ data_drift_analysis.ipynb
â”œâ”€â”€ api_performance_analysis.py
â””â”€â”€ logs/
    â””â”€â”€ api_logger.log
```

---

## âš™ï¸ Installation et exÃ©cution locale

### 1ï¸âƒ£ Cloner le projet
```bash
git clone https://github.com/RomaneFatima-Zahra/P8_ApiCreditPrediction
cd P8_ApiCreditPrediction
```

### 2ï¸âƒ£ CrÃ©er un environnement virtuel
```bash
python -m venv venv
source venv/bin/activate  # Linux / macOS
venv\Scripts\activate   # Windows
```

### 3ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Lancer lâ€™API
```bash
uvicorn API_Fastapi:app --reload --port 7860
```

Lâ€™API sera disponible sur :  
ğŸ‘‰ [http://localhost:7860](http://localhost:7860)

---

## ğŸ§© Endpoints disponibles

| MÃ©thode | Route        | Description |
|----------|--------------|-------------|
| `GET`    | `/`          | Page dâ€™accueil |
| `POST`   | `/predict`   | PrÃ©diction de solvabilitÃ© |
| `GET`    | `/logs`      | Lecture des logs |
| `GET`    | `/favicon.ico` | IgnorÃ© |

---

## ğŸ“¤ Exemple dâ€™appel Ã  lâ€™API

```bash
curl -X 'POST' \
  'http://127.0.0.1:7860/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
"NAME_CONTRACT_TYPE": "Revolving loans",
    "CODE_GENDER": "F",
    "FLAG_OWN_CAR": "N",
    "FLAG_OWN_REALTY": "Y",
    "CNT_CHILDREN": 0,
    "AMT_INCOME_TOTAL": 121500.0,
    "AMT_CREDIT": 180000.0,
    "AMT_ANNUITY": 9000.0,
    "AMT_GOODS_PRICE": 180000.0,
    "NAME_TYPE_SUITE": "Unaccompanied",
    "NAME_INCOME_TYPE": "Working",
    "NAME_EDUCATION_TYPE": "Incomplete higher",
    "NAME_FAMILY_STATUS": "Separated",
    "NAME_HOUSING_TYPE": "House / apartment",
    "REGION_POPULATION_RELATIVE": 0.022625,
    "DAYS_BIRTH": -10335,
    "DAYS_EMPLOYED": -484,
    "DAYS_REGISTRATION": -2322.0,
    "DAYS_ID_PUBLISH": -2468,
    "FLAG_EMP_PHONE": 1,
    "FLAG_WORK_PHONE": 1,
    "FLAG_PHONE": 1,
    "FLAG_EMAIL": 0,
    "OCCUPATION_TYPE": "Laborers",
    "CNT_FAM_MEMBERS": 1.0,
    "REGION_RATING_CLIENT": 2,
    "REGION_RATING_CLIENT_W_CITY": 2,
    "WEEKDAY_APPR_PROCESS_START": "WEDNESDAY",
    "HOUR_APPR_PROCESS_START": 12,
    "REG_REGION_NOT_LIVE_REGION": 0,
    "REG_REGION_NOT_WORK_REGION": 0,
    "LIVE_REGION_NOT_WORK_REGION": 0,
    "REG_CITY_NOT_LIVE_CITY": 0,
    "REG_CITY_NOT_WORK_CITY": 0,
    "LIVE_CITY_NOT_WORK_CITY": 0,
    "ORGANIZATION_TYPE": "Industry: type 3",
    "FLOORSMAX_AVG": 0.3333,
    "LIVINGAREA_AVG": 0.2647,
    "YEARS_BEGINEXPLUATATION_MODE": 0.994,
    "OBS_30_CNT_SOCIAL_CIRCLE": 0.0,
    "DEF_30_CNT_SOCIAL_CIRCLE": 0.0,
    "DAYS_LAST_PHONE_CHANGE": -542.0,
    "PREVIOUS_LOANS_COUNT": 4.0,
    "CREDIT_INCOME_PERCENT": 1.4814814814814814,
    "ANNUITY_INCOME_PERCENT": 0.074074074074074,
    "CREDIT_TERM": 0.05,
    "DAYS_EMPLOYED_PERCENT": 0.0468311562651185
}'

```
Exemple de rÃ©ponse :
```json

{
  "prediction": "DÃ©faillant",
  "probabilitÃ©_defaut": 0.5101
}

```

---

## ğŸ§ª Tests  

Les tests unitaires et dâ€™intÃ©gration sont gÃ©rÃ©s avec **pytest** et **pytest-cov** afin de garantir la fiabilitÃ© du modÃ¨le et de mesurer la couverture du code.  

### â–¶ï¸ Lancer la suite de tests (depuis la racine du projet)  
```bash
pytest -v
```

### ğŸ“Š GÃ©nÃ©rer le rapport de couverture  
```bash
pytest --cov=. --cov-report=term-missing
```

### ğŸŒ GÃ©nÃ©rer un rapport HTML dÃ©taillÃ©  
```bash
pytest --cov=. --cov-report=html
```
Le rapport sera disponible dans le dossier `htmlcov/` :  
`htmlcov/index.html` (ouvrable avec votre navigateur).  

---

### ğŸ§± Structure des tests  

Les tests sont rÃ©partis en deux fichiers :  
- **`test_unitaires.py`** â†’ vÃ©rifie les modÃ¨les Pydantic et les endpoints unitaires.  
- **`test_integration.py`** â†’ teste le comportement global de lâ€™API et les scÃ©narios complets de prÃ©diction.  

---

### âœ… Tests implÃ©mentÃ©s  

| CatÃ©gorie | Test | Description |
|------------|------|-------------|
| **Unitaires (Pydantic & endpoints)** | `test_client_data_valid` | VÃ©rifie la crÃ©ation dâ€™un objet `ClientData` valide. |
|  | `test_client_data_invalid_values` | VÃ©rifie la validation des contraintes et des erreurs. |
|  | `test_enum_values` | VÃ©rifie les valeurs possibles des Ã©numÃ©rations (`CODE_GENDER`, `NAME_CONTRACT_TYPE`). |
|  | `test_home_endpoint` | VÃ©rifie la route racine `/`. |
|  | `test_predict_endpoint_success` | VÃ©rifie lâ€™endpoint `/predict` avec un client valide (mock du modÃ¨le). |
|  | `test_predict_endpoint_defaillant` | VÃ©rifie le comportement pour un client dÃ©faillant. |
|  | `test_predict_endpoint_invalid_data` | VÃ©rifie la gestion dâ€™entrÃ©es invalides (422). |
|  | `test_predict_endpoint_model_not_loaded` | VÃ©rifie le message dâ€™erreur si le modÃ¨le nâ€™est pas chargÃ© (500). |
| **IntÃ©gration (workflow complet)** | `test_complete_workflow` | VÃ©rifie le parcours complet `/ â†’ predict`. |
|  | `test_multiple_predictions` | VÃ©rifie plusieurs prÃ©dictions consÃ©cutives avec des clients diffÃ©rents. |
|  | `test_error_handling` | VÃ©rifie la robustesse face Ã  des erreurs de validation. |
|  | `test_enum_validation` | VÃ©rifie les erreurs sur valeurs dâ€™Ã©numÃ©ration invalides. |
|  | `test_response_format` | VÃ©rifie la structure et les types de donnÃ©es de la rÃ©ponse JSON. |

---

## ğŸ§° Dockerisation

La dockerisation permet dâ€™encapsuler lâ€™API FastAPI et son modÃ¨le de Machine Learning dans un conteneur lÃ©ger et portable.
Cela garantit une exÃ©cution identique sur tous les environnements (local, cloud, CI/CD) et simplifie le dÃ©ploiement.

### ğŸ¯ Objectif

Faciliter le dÃ©ploiement de lâ€™API sans dÃ©pendances locales.

Garantir un environnement reproductible entre les machines de dÃ©veloppement, test et production.

Simplifier le scaling horizontal (plusieurs instances conteneurisÃ©es derriÃ¨re un load balancer).

```bash

docker build -t api_default_prediction:latest .
```
ğŸ“¦ CrÃ©e une image Ã  partir du Dockerfile Ã  la racine du projet.

```bash
docker run -d -p 7860:7860 --name test-api api_default_prediction:latest
```
ğŸš€ ExÃ©cute le conteneur en arriÃ¨re-plan (-d) et mappe le port 7860 du conteneur sur le port 7860 de la machine hÃ´te.
Lâ€™API devient accessible Ã  lâ€™adresse : http://localhost:7860

### Dockerfile 

FROM python:3.12.2-slim â†’ image Python optimisÃ©e, lÃ©gÃ¨re, adaptÃ©e Ã  la production.

WORKDIR /app â†’ dÃ©finit le dossier de travail du conteneur.

COPY . /app â†’ copie le code source, y compris model.pkl, dans le conteneur.

RUN apt-get ... â†’ installe les outils nÃ©cessaires pour compiler dâ€™Ã©ventuelles dÃ©pendances (scikit-learn, numpy, etc.).

RUN pip install ... â†’ installe les dÃ©pendances Python du projet listÃ©es dans requirements.txt.

EXPOSE 7860 â†’ indique le port sur lequel lâ€™API sera disponible Ã  lâ€™extÃ©rieur du conteneur.

CMD [...] â†’ commande exÃ©cutÃ©e au dÃ©marrage : lance le serveur Uvicorn pour exÃ©cuter lâ€™API FastAPI.
---

## ğŸªµ Logs et monitoring

La journalisation (logging) permet de suivre lâ€™activitÃ© de lâ€™API, diagnostiquer les erreurs, et surveiller les performances en production.
Les logs sont structurÃ©s et enregistrÃ©s automatiquement dans le dossier :
```
logs/api_logger.log
```
### ğŸ¯ Objectif

Assurer une traÃ§abilitÃ© complÃ¨te des requÃªtes et rÃ©ponses.

Identifier rapidement les erreurs ou anomalies.

Faciliter le debugging, lâ€™analyse post-dÃ©ploiement et la supervision (monitoring).

### ğŸ§© Contenu des logs

Chaque entrÃ©e du fichier api_logger.log contient les informations suivantes :

ğŸ•’ **Timestamp**	: Date et heure de lâ€™Ã©vÃ©nement (format ISO 8601).
âš™ï¸ **Niveau** : 	Niveau de gravitÃ© (INFO, WARNING, ERROR, CRITICAL).
ğŸ§© **Module/Fonction**	: Emplacement du log dans le code (ex : predict, startup_event).
ğŸ§  **Message** : 	DÃ©tail du message (ex : â€œRequÃªte reÃ§ue pour un client solvableâ€).

--

## âš™ï¸ Pipeline CI/CD (GitHub Actions)

### ğŸ¯ Objectif  
Automatiser les **tests**, la **construction Docker** et la **validation du code** Ã  chaque modification du dÃ©pÃ´t GitHub.  
Ce pipeline assure une intÃ©gration continue fiable et reproductible, garantissant la stabilitÃ© avant tout dÃ©ploiement.

---

### ğŸ§© DÃ©clenchement du pipeline  
Le workflow GitHub Actions sâ€™exÃ©cute automatiquement :  
- Ã  chaque **push** sur la branche `main`,  
- et Ã  chaque **pull request** vers `main`.

---

### ğŸ§± Structure du pipeline  

Le pipeline est composÃ© de **deux jobs principaux**, exÃ©cutÃ©s dans cet ordre :  

| Ã‰tape | Nom du job | Objectif principal |
|--------|-------------|--------------------|
| ğŸ§ª **Job 1** | `test` | ExÃ©cuter les tests unitaires et dâ€™intÃ©gration |
| ğŸ³ **Job 2** | `build` | Construire et valider lâ€™image Docker de lâ€™API |


> ğŸ”„ En cas dâ€™Ã©chec sur les tests, la phase de build est automatiquement interrompue (`needs: test`).  

---

### ğŸ§ª Job 1 â€” Tests automatisÃ©s  

**Nom complet :** `Run Tests unitaires et intÃ©gration`  
**Environnement :** `ubuntu-latest`  
**DurÃ©e moyenne :** ~2 minutes  

#### Ã‰tapes clÃ©s :  
1. **Checkout du code** â†’ rÃ©cupÃ©ration du dÃ©pÃ´t (`actions/checkout@v4`)  
2. **Installation de Python 3.12** â†’ via `actions/setup-python@v4`  
3. **Installation des dÃ©pendances** â†’ depuis `requirements.txt`  
4. **ExÃ©cution des tests** :
   ```bash
   python -m pytest test_unit.py -v
   python -m pytest test_integration.py -v
   ```
5. **RÃ©sultat attendu :**
   - âœ… Tous les tests passent avant dâ€™autoriser le build  
   - âŒ En cas dâ€™Ã©chec â†’ le pipeline sâ€™arrÃªte immÃ©diatement  

---

### ğŸ³ Job 2 â€” Build de lâ€™image Docker  

**Nom complet :** `Build de Docker Image`  
**Condition dâ€™exÃ©cution :** uniquement si le job `test` est rÃ©ussi (`needs: test`)  
**DurÃ©e moyenne :** ~3 Ã  4 minutes  

#### Ã‰tapes clÃ©s :  
1. **Re-clonage du dÃ©pÃ´t**  
2. **Configuration de lâ€™environnement Docker Buildx** (`docker/setup-buildx-action@v3`)  
3. **Construction de lâ€™image** :  
   ```bash
   docker build -t api_default_prediction:latest .
   ```
4. **Test de lâ€™image construite** :  
   Lancement temporaire du conteneur et test du endpoint `/` :  
   ```bash
   docker run -d -p 7860:7860 --name test-api api_default_prediction:latest
   sleep 10
   curl -f http://localhost:7860/ || exit 1
   docker stop test-api
   ```
5. **Sauvegarde de lâ€™image Docker** :  
   ```bash
   docker save api_default_prediction:latest -o image.tar
   ```
6. **Upload de lâ€™artefact Docker** (fichier `image.tar`) via :  
   ```yaml
   uses: actions/upload-artifact@v4
   ```
   â†’ Retenu 1 jour pour vÃ©rification manuelle.  

---

### ğŸ“Š RÃ©sumÃ© des points de contrÃ´le  

| Ã‰lÃ©ment | VÃ©rification | Statut attendu |
|----------|--------------|----------------|
| âœ… Tests unitaires | 100% des tests passent | ğŸŸ¢ OK |
| ğŸ§± Build Docker | Image construite et testÃ©e | ğŸŸ¢ OK |
| ğŸ“¦ Artefact Docker | UploadÃ© avec succÃ¨s | ğŸŸ¢ OK |
| ğŸ”” Notifications | En cas dâ€™Ã©chec | ğŸŸ  Automatique via GitHub Actions |

---

### ğŸ† Bonnes pratiques mises en Å“uvre  

- âœ… **SÃ©paration claire des responsabilitÃ©s** : un job pour les tests, un autre pour le build  
- âœ… **DÃ©pendance explicite** entre jobs (`needs: test`)  
- âœ… **Actions officielles** :  
  - `actions/checkout@v4`  
  - `actions/setup-python@v4`  
  - `docker/setup-buildx-action@v3`  
  - `actions/upload-artifact@v4`  
- âœ… **Validation Docker automatisÃ©e** (vÃ©rification de disponibilitÃ© du service via `curl`)  
- âœ… **ReproductibilitÃ©** : chaque run CI/CD est isolÃ© et cohÃ©rent  

---

### ğŸ§­ RÃ©sumÃ© global du workflow  

| Ã‰tape | Description | DurÃ©e estimÃ©e |
|--------|--------------|---------------|
| ğŸ§ª Tests | Validation du code et du modÃ¨le | ~2 min |
| ğŸ³ Build Docker | Construction + test du conteneur | ~3 min |
| ğŸ“¦ Upload artefact | Sauvegarde de lâ€™image Docker | ~1 min |

> ğŸ”„ Total : environ **6 minutes** du push au build complet.

--

# ğŸ“Š Monitoring et Analyse AvancÃ©e

Le projet comprend **des modules complÃ©mentaires** pour superviser les performances, la qualitÃ© des donnÃ©es et la fiabilitÃ© du modÃ¨le.

---

## ğŸ–¥ï¸ 1. `app_monitoring.py` â€“ Tableau de bord Streamlit

Une interface **Streamlit** interactive pour :  
- Visualiser les prÃ©dictions et mÃ©triques de performance  
- Suivre les taux dâ€™erreurs, la latence, les pics de charge  
- GÃ©nÃ©rer des rapports visuels

```bash
streamlit run app_monitoring.py
```

Accessible sur : [http://localhost:8501](http://localhost:8501)

---

## ğŸ“ˆ 2. `data_drift_analysis.ipynb` â€“ Analyse de dÃ©rive des donnÃ©es

BasÃ©e sur **Evidently AI**, elle compare les distributions entre donnÃ©es historiques et rÃ©centes pour dÃ©tecter la **data drift**.

```bash
python data_drift_analysis.py
```

Sorties :  
- Rapport : `drift_report_temp.html`  
- Stats globales (latence, erreurs, dÃ©rive)

---
## âš¡ 3. `api_performance_analysis.py` â€“ Profilage et benchmark du modÃ¨le

Permet de mesurer les performances du modÃ¨le (`predict`, `predict_proba`) et dâ€™identifier les goulots dâ€™Ã©tranglement.

```bash
python api_performance_analysis.py
```

RÃ©sultats :  
- `performance_results/cprofile_predict.txt`  
- `performance_results/bottlenecks.json`  
- `performance_results/benchmark.log`

### MÃ©thodologie appliquÃ©e  

Lâ€™analyse de performance a consistÃ© Ã  Ã©valuer diffÃ©rentes stratÃ©gies de gestion du modÃ¨le de Machine Learning afin dâ€™**optimiser la vitesse de prÃ©diction** et la **rÃ©activitÃ© globale** de lâ€™API.  

#### Ã‰tapes de la dÃ©marche  
1. **Benchmark de rÃ©fÃ©rence (version naÃ¯ve)** â€” mesure des performances initiales.  
2. **Profilage `cProfile`** â€” identification des fonctions les plus coÃ»teuses dans le pipeline scikit-learn.  
3. **Optimisation ciblÃ©e** â€” mise en place de correctifs visant Ã  rÃ©duire la latence.  
4. **Mesure dâ€™impact** â€” comparaison quantitative avant / aprÃ¨s optimisation.  

#### âš¡ Optimisation principale : prÃ©chargement du modÃ¨le  
- **ProblÃ¨me identifiÃ© :** le modÃ¨le (~2,1 MB) Ã©tait rechargÃ© depuis le disque Ã  **chaque requÃªte**, gÃ©nÃ©rant une latence inutile.  
- **Solution implÃ©mentÃ©e :** utilisation du mÃ©canisme **`lifespan` de FastAPI** pour charger le modÃ¨le **une seule fois au dÃ©marrage** du serveur, puis le conserver en mÃ©moire pour toutes les prÃ©dictions ultÃ©rieures.  

#### ğŸ“Š RÃ©sultats du benchmark  

| Indicateur | Chargement Ã  chaque requÃªte | ModÃ¨le prÃ©chargÃ© | Gain |
|-------------|-----------------------------|------------------|------|
| Temps moyen (ms) | 4.938 | 1.366 | ğŸ”½ **âˆ’72.3 %** |
| P95 (ms) | 5.425 | 1.483 | ğŸ”½ **âˆ’72.6 %** |

#### ğŸ§  Analyse du profilage `cProfile`  
- âœ… **Goulot principal identifiÃ© :** `joblib.load()` reprÃ©sentant **72 % du temps total dâ€™exÃ©cution**.  
- âœ… **Optimisation confirmÃ©e :** suppression de ce rechargement rÃ©current = gain direct de performance.  
- ğŸ“„ **RÃ©sultats dÃ©taillÃ©s :** disponibles dans `performance_results/` (`cprofile_predict.txt`, `cprofile_proba.txt`, `profiling_results.txt`).  

#### ğŸš€ Impact global  
- Temps de rÃ©ponse API rÃ©duit de **plus de 70 %**.  
- StabilitÃ© amÃ©liorÃ©e (latence plus constante).  
- Aucune perte de prÃ©cision ni modification du comportement du modÃ¨le. 

#### âŒ  StratÃ©gies dâ€™optimisation non retenues â€” rÃ©sumÃ©

Plusieurs autres pistes dâ€™optimisation ont Ã©tÃ© explorÃ©es mais Ã©cartÃ©es aprÃ¨s expÃ©rimentation :

**Conversion en format ONNX** â†’ incompatible avec certaines Ã©tapes du pipeline scikit-learn (ColumnTransformer, Encoder) et gain marginal (<10%).

**Rechargement asynchrone du modÃ¨le** â†’ inutile car le modÃ¨le est dÃ©jÃ  prÃ©chargÃ© via le lifespan FastAPI et les prÃ©dictions sont non asynchrones.

**ParallÃ©lisation (multiprocessing / ThreadPool)** â†’ redondante avec le parallÃ©lisme interne de scikit-learn (n_jobs=-1), ajoutant de la complexitÃ© sans gain rÃ©el.

**Mise en cache des prÃ©dictions** â†’ inapplicable, car chaque client possÃ¨de des donnÃ©es uniques, rendant le cache inefficace et risquÃ© pour la confidentialitÃ©.

**AccÃ©lÃ©ration GPU**  â†’ non pertinente : scikit-learn ne tire pas parti du GPU et le modÃ¨le est trop lÃ©ger pour compenser la latence dâ€™E/S GPU.

----

## ğŸ‘¨â€ğŸ’» Auteur

**Nom :** Fatima-Zahra BARHOU  
**Version :** 3.0  
**Licence :** MIT
